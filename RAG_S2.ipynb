{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWMbG2gIh26PYnj1QSn4LZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramanakurva164/genai/blob/main/RAG_S2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VToOUNtp3mnM",
        "outputId": "1ef1311f-78e6-4086-a12d-1aa3f67a9ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.30.0 in /usr/local/lib/python3.11/dist-packages (4.30.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.30.0 faiss-cpu torch # Install necessary libraries: transformers for models, faiss-cpu for efficient similarity search, and torch for tensor operations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INGESTION\n"
      ],
      "metadata": {
        "id": "_jQ_Mn-x3vCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text=\"The Amazon rainforest is a vast and biodiverse ecosystem located primarily in Brazil, but also spanning across several other South American countries. It's home to an incredibly diverse range of plant and animal species, many of which are found nowhere else on Earth. The rainforest plays a crucial role in regulating the global climate, absorbing large amounts of carbon dioxide and releasing oxygen. Deforestation, driven by activities such as agriculture and logging, poses a significant threat to the Amazon's biodiversity and its ability to regulate the climate. Protecting the Amazon is vital for both environmental and human well-being.\" # Define a sample text string about the Amazon rainforest."
      ],
      "metadata": {
        "id": "YinIGjZc3t2T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMBEDDINGS\n",
        "\"sentence-transformers for embedding keyword\n",
        "\""
      ],
      "metadata": {
        "id": "_glvveCe3zbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer # Import AutoModel and AutoTokenizer classes from the transformers library for loading pre-trained models and tokenizers.\n",
        "import torch # Import the torch library for tensor operations.\n",
        "import numpy as np # Import the numpy library for numerical operations, specifically for converting tensors to numpy arrays.\n",
        "\n",
        "# Define the name of the pre-trained model to use for embeddings.\n",
        "model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "# Load the tokenizer associated with the chosen model.\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
        "# Load the pre-trained model.\n",
        "model=AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Define a function to generate embeddings for a given text.\n",
        "def get_embeddings(text):\n",
        "  # Tokenize the input text, returning PyTorch tensors, truncating to the model's max length, and padding for uniform input size.\n",
        "  tokens=tokenizer(text,return_tensors=\"pt\",truncation=True,padding=True) #token= words ; truncation: uniform input; padding:\n",
        "  # Disable gradient calculation for efficiency during inference.\n",
        "  with torch.no_grad(): # to only generate responses not to train itself\n",
        "    # Pass the tokenized input to the model to get the output.\n",
        "    output = model(**tokens) #** for unwrapping\n",
        "  # Get the last hidden state, calculate the mean across the token dimension, remove the singleton dimension, and convert to a numpy array.\n",
        "  return output.last_hidden_state.mean(dim=1).squeeze().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5w4si1M31Ai",
        "outputId": "651f342c-044f-486f-9d8d-456ff2d5faed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHUNKING\n"
      ],
      "metadata": {
        "id": "Y75z-CZn8qyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss # Import the faiss library for efficient similarity search.\n",
        "chunks=[sample_text] # Create a list of text chunks (in this case, just the sample text).\n",
        "embeddings=[get_embeddings(chunk) for chunk in chunks] # Generate embeddings for each chunk using the get_embeddings function.\n",
        "dim=len(embeddings[0]) # Determine the dimension of the embeddings.\n",
        "\n",
        "index=faiss.IndexFlatL2(dim) ## Create a FlatL2 index in faiss with the specified dimension, which uses L2 (Euclidean) distance.\n",
        "index.add(np.array(embeddings)) # Add the calculated embeddings to the faiss index."
      ],
      "metadata": {
        "id": "q_of8XzZ8s2-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieving"
      ],
      "metadata": {
        "id": "ngQRal4G-Bmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline # Import the pipeline function from the transformers library for easy use of pre-trained models.\n",
        "\n",
        "# Create a question answering pipeline using a pre-trained DistilBERT model and specifying PyTorch as the framework.\n",
        "qa_pipeline=pipeline(\"question-answering\",model=\"distilbert-base-cased-distilled-squad\", framework=\"pt\")\n",
        "\n",
        "# Define a function to retrieve relevant text based on a query and answer the question.\n",
        "def retrive_and_answer(query,top_k=1):\n",
        "      # Generate the embedding for the query and reshape it for faiss search.\n",
        "      query_embedding=get_embeddings(query).reshape(1,-1)\n",
        "      # Search the faiss index for the top_k most similar embeddings to the query embedding.\n",
        "      _,indices=index.search(query_embedding,top_k)\n",
        "      # Retrieve the text chunks corresponding to the indices found in the search.\n",
        "      retrived_text= [chunks[i] for i in indices[0]]\n",
        "      # Join the retrieved text chunks to form the context for the question answering model.\n",
        "      context=\"\".join(retrived_text)\n",
        "      # Pass the question and context as a dictionary to the question answering pipeline.\n",
        "      answer=qa_pipeline({'question': query, 'context': context})\n",
        "      # Return the answer from the pipeline's output.\n",
        "      return answer['answer']"
      ],
      "metadata": {
        "id": "ZKqAgh1m-FDs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is this document about?\" # Define the query string.\n",
        "answer = retrive_and_answer(query) # Call the retrieve_and_answer function with the query to get the answer.\n",
        "print(answer) # Print the retrieved answer."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Z0QNFoCLmy",
        "outputId": "92e44190-cea2-41e8-f2d0-b30b23769465"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Protecting the Amazon is vital for both environmental and human well-being\n"
          ]
        }
      ]
    }
  ]
}